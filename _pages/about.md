---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I am a research assistant in the CITI at Academia Sinica, working with [Prof. Jun-Cheng Chen](https://scholar.google.com/citations?user=3x9KITUAAAAJ&hl=en). Previously, I served as a research assistant at the Institute of Information Science, Academia Sinica, under the supervision of [Prof. Chun-Shien Lu](https://scholar.google.com/citations?user=3iOHvUAAAAAJ&hl) and co-advised by [Prof. Chia-Mu Yu](https://scholar.google.com/citations?user=dW4W4isAAAAJ&hl) during this time. 

I obtained two M.Sc. degrees: one in Computer Science from National Chengchi University, Taiwan (advised by Prof. [Prof. Raylin Tso](https://scholar.google.com/citations?user=go8aLaQAAAAJ&hl)), and another in Electrical Engineering & Computer Science from Kanazawa University, Japan (advised by Prof. [Prof. Masahiro Mambo](https://iseclab.ec.t.kanazawa-u.ac.jp/en/mambo/index.html)). I received my B.Sc. degree in Information Management from Chang Gung University, Taiwan.


### Research Interest

My primary research interests focus on developing **trustworthy and reliable AI systems** to advance technology and address social challenges. I aim to ensure **robustness, privacy, fairness, and interpretability of AI** when applied across various domains.


<!-- ![My Research Interest in Trustworthy AI](/images/future_research_overview.jpg) -->
<!-- > *My Research Interest in Trustworthy AI* -->

I'm currently exploring the following research topics:
* Robustness of Deep Learning
* Responsibility of collaborative AI
* Trustworthy AI + X (Applications): Cybersecurity

<!-- My research interests include <strong>trustworthy AI</strong> and <strong>adversarial machine learning</strong>, with my Ph.D. thesis specifically focusing on poisoning attacks and defenses against deep neural networks. I'm currently working on enhancing the robustness of foundation models and their integration into traditional machine learning systems. -->

<!-- ![My Research Journey in Adversarial Machine Learning](/images/past_work.png) -->
<!-- > *My Research Journey in Adversarial Machine Learning* -->

<!-- My research vision is centered on developing trustworthy and reliable AI systems, aiming to support the advancement of technology and solve social challenges. I am keen to broaden my research scope to encompass the concept of <strong>responsibility</strong> in machine learning, focusing on areas such as <strong>robustness, fairness, and interpritability</strong>. Recently, I'm exploring the following research topics: -->

### News

<div style="height: 300px; overflow-y: scroll;">
  <ul>
    <li>2025-07-12: Our paper is accepted to ECAI 2025: "BadVim: Unveiling Backdoor Threats in Visual State Space Model".</li>
    <li>2024-09-01: Our paper is accepted to WACV 2025: "Defending Against Repetitive Backdoor Attacks on Semi-supervised Learning through Lens of Rate-Distortion-Perception Trade-off".</li>
    <li>2024-04-12: Our paper is accepted to ICME 2024 <strong>[Oral]</strong>: "On The Higher Moment Disparity of Backdoor Attacks".</li>
    <li>2024-03-20: I obtained my M.S. Degree in Electrical Engineering & Computer Science from Kanazawa University, Japan.</li>
  </ul>
</div>


### Professional Service
<ul>
    <li>
        <strong>Conference Reviewer</strong>
        <ul>
            <li>IEEE International Conference on Multimedia and Expo (ICME), 2024, 2025</li>
        </ul>
    </li>
</ul>


For more info
------
More info about configuring Academic Pages can be found in [the guide](https://academicpages.github.io/markdown/), the [growing wiki](https://github.com/academicpages/academicpages.github.io/wiki), and you can always [ask a question on GitHub](https://github.com/academicpages/academicpages.github.io/discussions). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
