---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hi! üëã I am a research assistant in CITI at Academia Sinica, working with Prof. [Jun-Cheng Chen](https://scholar.google.com/citations?user=3x9KITUAAAAJ&hl=en). Previously, I served as a research assistant at the Institute of Information Science, Academia Sinica, under the supervision of Prof. [Chun-Shien Lu](https://scholar.google.com/citations?user=3iOHvUAAAAAJ&hl) and co-advised by Prof. [Chia-Mu Yu](https://scholar.google.com/citations?user=dW4W4isAAAAJ&hl) during this time. 

I obtained two M.Sc. degrees: one in Computer Science from National Chengchi University, Taiwan (advised by Prof. [Raylin Tso](https://scholar.google.com/citations?user=go8aLaQAAAAJ&hl)), and another in Electrical Engineering & Computer Science from Kanazawa University, Japan (advised by Prof. [Masahiro Mambo](https://iseclab.ec.t.kanazawa-u.ac.jp/en/mambo/index.html)). I received my B.Sc. degree in Information Management from Chang Gung University, Taiwan.


## üî¨ Research Interest

My primary research interests focus on developing **trustworthy and reliable AI systems** to advance technology and address social challenges. I aim to ensure **robustness, privacy, fairness, and interpretability of AI** when applied across various domains.


<!-- ![My Research Interest in Trustworthy AI](/images/future_research_overview.jpg) -->
<!-- > *My Research Interest in Trustworthy AI* -->

I'm currently exploring the following research topics:
* Robustness of Deep Learning
* Responsibility of collaborative AI
* Trustworthy AI + X (Applications): Cybersecurity

<!-- My research interests include <strong>trustworthy AI</strong> and <strong>adversarial machine learning</strong>, with my Ph.D. thesis specifically focusing on poisoning attacks and defenses against deep neural networks. I'm currently working on enhancing the robustness of foundation models and their integration into traditional machine learning systems. -->

<!-- ![My Research Journey in Adversarial Machine Learning](/images/past_work.png) -->
<!-- > *My Research Journey in Adversarial Machine Learning* -->

<!-- My research vision is centered on developing trustworthy and reliable AI systems, aiming to support the advancement of technology and solve social challenges. I am keen to broaden my research scope to encompass the concept of <strong>responsibility</strong> in machine learning, focusing on areas such as <strong>robustness, fairness, and interpritability</strong>. Recently, I'm exploring the following research topics: -->

## üì¢ News

<div style="height: 150px; overflow-y: scroll;">
  <ul>
    <li>2025-07-12: Our paper is accepted to ECAI 2025: "BadVim: Unveiling Backdoor Threats in Visual State Space Model".</li>
    <li>2024-09-01: Our paper is accepted to WACV 2025: "Defending Against Repetitive Backdoor Attacks on Semi-supervised Learning through Lens of Rate-Distortion-Perception Trade-off".</li>
    <li>2024-04-12: Our paper is accepted to ICME 2024 <strong>[Oral]</strong>: "On The Higher Moment Disparity of Backdoor Attacks".</li>
  </ul>
</div>

## üìù Professional Service 
- **Conference Reviewer**
  - IEEE ICME (2024, 2025)
  
### For more info
------
Feel free to reach out at chengyi.lee.1224 [AT] gmail.com for potential collaborations or discussions.
